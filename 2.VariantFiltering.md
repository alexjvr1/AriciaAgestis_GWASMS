# Filtering raw variants

## ddRAD data


Filtering variants from the raw vcf output to produce one dataset:

1. GWAS analysis using BSLMM (include as many loci as possible).


### Filters to apply

1. Remove loci with QUAL < 20 (i.e. Phred confidence in variant site)

2. Minimum mean depth of 6 (i.e. remove loci with lower than mean 6x depth)

3. Max mean depth of mean + 2xSD of meanDP (here 500)

4. remove all multi-allelic SNPs

5. Remove all loci genotyped in <30% of individuals

6. Remove individuals with >60% missingness


Working directory 
```
/newhome/aj18951/1a_Aricia_agestis_GWASdata/03_variants
```


The initial variants.raw.bcf file 
```
#Concatenate all the individual bcf files that have been called (one for each chromosome)
module load apps/bcftools-1.8

ls *raw.bcf > FILE
bcftools concat -O b -a -d none -f FILE > Aagestis.raw.bcf


#The raw bcf files need to be processed to "see" missing data

bcftools filter -S . -O u -e 'FMT/DP=0' Aagestis.raw.bcf |bcftools view -O b -o Aagestis.withmissing.bcf

#If you want to run this per chromosome.. 
#for i in $(ls *bcf); do bcftools filter -S . -O u -e 'FMT/DP=0' $i |bcftools view -O b -o $i.withmissing.bcf; done

#You can view the bcf file with bcftools. Check that the 0 depth genotypes have been called as missing (./.) and not REF (0/0)
bcftools view Aagestis.withmissing.bcf |less

#convert the bcf to vcf
bcftools convert -O v Aagestis.withmissing.bcf -o Aagestis.withmissing.vcf
```


Now we can start filtering. First filter on depth 
```
Dataset1

#We're using vcftools to filter the dataset
module load apps/vcftools-0.1.12b

#First get a list of all the sample names. There are two populations (GTT and TP) that we won't use for the GWAS so they need to be removed. 

bcftools query -l Aagestis.withmissing.vcf > samplenames

grep GTT samplenames > toremove
GTT_1_R1_.fastq.gz
GTT_3_R1_.fastq.gz
GTT_4_R1_.fastq.gz
GTT_5_R1_.fastq.gz
GTT_6_R1_.fastq.gz

grep TP samplenames >> toremove
TP_31_R1_.fastq.gz
TP_32_R1_.fastq.gz
TP_33_R1_.fastq.gz
TP_43_R1_.fastq.gz
TP_44_R1_.fastq.gz

##And add the individuals we've determined are more related than expecte (see below)
LYD_29_2014_R1_.fastq.gz
BRO_24_2013_R1_.fastq.gz
BRO_6_2013_R1_.fastq.gz
HOD_27_2014_R1_.fastq.gz
WIS_39_2014_R1_.fastq.gz
WIS_13_2013_R1_.fastq.gz
WIS_15_2013_R1_.fastq.gz
WIS_22_2013_R1_.fastq.gz
WIS_28_2013_R1_.fastq.gz
WIS_16_2013_R1_.fastq.gz
WIS_24_2013_R1_.fastq.gz
HOD_27_2014_R1_.fastq.gz
BRO_21_2013_R1_.fastq.gz
SWD_9_2014_R1_.fastq.gz



vcftools --vcf Aagestis.withmissing.vcf --remove toremove --recode --recode-INFO-all --out AAgestis.withmissing.263_FINAL

Parameters as interpreted:
	--vcf Aagestis.withmissing.vcf
	--exclude toremove
	--recode-INFO-all
	--out AAgestis.withmissing.262_FINAL
	--recode

Excluding individuals in 'exclude' list
After filtering, kept 263 out of 286 Individuals
Outputting VCF file...
After filtering, kept 558840 out of a possible 558840 Sites
Run Time = 328.00 seconds



#implement some initial basic filters 
vcftools --vcf AAgestis.withmissing.263_FINAL.recode.vcf --minQ 20 --min-meanDP 6 --max-alleles 2 --max-missing 0.3 --recode --recode-INFO-all --out AAgestis_FINAL

Parameters as interpreted:
	--vcf AAgestis.withmissing.263_FINAL.recode.vcf
	--recode-INFO-all
	--max-alleles 2
	--min-meanDP 6
	--minQ 20
	--max-missing 0.3
	--out AAgestis_FINAL
	--recode

After filtering, kept 263 out of 263 Individuals
Outputting VCF file...
After filtering, kept 134992 out of a possible 558840 Sites
Run Time = 124.00 seconds



#We need to find the max Depth filter. We have this because some loci might've incorrectly been lumped together (e.g gene duplicates or very similar genetic regions). Typically these will have ~2x the coverage of the other loci. So we need to find the mean depth across all loci and then find the cut-off

vcftools --vcf AAgestis_FINAL.recode.vcf --site-mean-depth

awk '!/IN/' out.ldepth.mean | cut -f3 > lmeandepth

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
binwidth=0.1
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'lmeandepth' using (bin( $1,binwidth)):(1000.0) smooth freq with boxes
pause -1
EOF

#Find the median depth + 2xSD
awk -F '\t' '{sum+=$3}END{print sum/NR}' out.ldepth.mean 
215.104    #mean

awk '{sum+=$3; a[NR]=$3}END{for(i in a)y+=(a[i]-(sum/NR))^2;print sqrt(y/(NR-1))}' out.ldepth.mean
214.811

Depth cut-off = 215.104 + 2x214.811 = 644.726


vcftools --vcf AAgestis_FINAL.recode.vcf --minQ 20 --min-meanDP 6 --max-meanDP 645 --max-alleles 2 --max-missing 0.3 --recode --recode-INFO-all --out AAgestis_FINAL2

VCFtools - v0.1.12b
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AAgestis_FINAL.recode.vcf
	--recode-INFO-all
	--max-alleles 2
	--max-meanDP 645
	--min-meanDP 6
	--minQ 20
	--max-missing 0.3
	--out AAgestis_FINAL2
	--recode

After filtering, kept 263 out of 263 Individuals
Outputting VCF file...
After filtering, kept 128876 out of a possible 134992 Sites
Run Time = 89.00 seconds

```

![alt_txt][Fig1.ldepth]

[Fig1.ldepth]:https://user-images.githubusercontent.com/12142475/117978948-4efaf500-b32a-11eb-87aa-f71957b072cb.png



Remove individuals with a high proportion of missingness.

```
vcftools --vcf AAgestis_FINAL2.recode.vcf --missing-indv

awk '!/IN/' out.imiss | cut -f5 > totalmissing

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin( $1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF
```
The vast majority of the samples have <30% missing data, although there are a few with up to 100% missingness


![alt_txt][Fig1.missingdata]

[Fig1.missingdata]:https://user-images.githubusercontent.com/12142475/117981689-2d4f3d00-b32d-11eb-8d1b-9eac1ac81847.png


```
#Remove individuals with >60% missingness

awk '$5>0.6 {print $1}' out.imiss > indivstoremove

cat indivstoremove

INDV
BAR_1_2013_R1_.fastq.gz
BAR_23_2014_R1_.fastq.gz
BCH_38_2013_R1_.fastq.gz
BRO_4_2014_R1_.fastq.gz
HOD_13_2014_R1_.fastq.gz
HOD_18_2014_R1_.fastq.gz
HOD_6_2014_R1_.fastq.gz
HOD_8_2014_R1_.fastq.gz
LYD_20_2014_R1_.fastq.gz
LYD_28_2014_R1_.fastq.gz
MOF_42_2014_R1_.fastq.gz
SWD_17_2013_R1_.fastq.gz
```


Remove samples

```
vcftools --vcf AAgestis_FINAL2.recode.vcf --remove indivstoremove --recode --recode-INFO-all --out AAgestis.251_FINAL

VCFtools - v0.1.12b
(C) Adam Auton and Anthony Marcketta 2009

VCFtools - v0.1.12b
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AAgestis_FINAL2.recode.vcf
	--exclude indivstoremove
	--recode-INFO-all
	--out AAgestis.251_FINAL
	--recode

Excluding individuals in 'exclude' list
After filtering, kept 251 out of 263 Individuals
Outputting VCF file...
After filtering, kept 128876 out of a possible 128876 Sites
Run Time = 76.00 seconds


#And check if the filters remove any more loci:

vcftools --vcf AAgestis.251_FINAL.recode.vcf --minQ 20 --min-meanDP 6 --max-missing 0.3 --recode --recode-INFO-all --out AAgestis.251_FINAL.recode.vcf

VCFtools - v0.1.12b
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AAgestis.261_FINAL.recode.vcf
	--recode-INFO-all
	--min-meanDP 6
	--minQ 20
	--max-missing 0.3
	--out AAgestis.251_FINAL.recode.vcf
	--recode

After filtering, kept 251 out of 251 Individuals
Outputting VCF file...
After filtering, kept 128843 out of a possible 128876 Sites
Run Time = 86.00 seconds


```

Rename the individuals in this file
```
module load apps/bcftools-1.8

bcftools query -l AAgestis.251_FINAL.recode.vcf > A251.oldnames

sed 's/_R1_.fastq.gz//g' A251.oldnames > A251.newnames

bcftools reheader AAgestis.251_FINAL.recode.vcf -s A251.newnames -o AAgestis.251_FINAL.newnames.vcf
```


### Assess the data

These stats are based on the dataset before filtering for MAF 1% (128843 loci)

You can use vcftools for this: 
```
module load apps/vcftools-0.1.17.2
```

OUTPUT DEPTH STATISTICS

--depth

Generates a file containing the mean depth per individual. This file has the suffix ".idepth".

--site-depth

Generates a file containing the depth per site summed across all individuals. This output file has the suffix ".ldepth".

--site-mean-depth

Generates a file containing the mean depth per site averaged across all individuals. This output file has the suffix ".ldepth.mean".


**NOTE

If there is a comma in a descriptor in the vcf header, you might get an error with the latest versions of vcftools.
```
Warning: Expected at least 2 parts in INFO entry: ID=PV4,Number=4,Type=Float,Description="P-values for strand bias, baseQ bias, mapQ bias and tail distance bias">
Warning: Expected at least 2 parts in INFO entry: ID=PV4,Number=4,Type=Float,Description="P-values for strand bias, baseQ bias, mapQ bias and tail distance bias">
Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description="Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases">
Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description="Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases">
```
Simply remove the comma in the Description="" part of the line. Or ignore the warning. See [here](https://github.com/vcftools/vcftools/issues/134) for validation. 


#### 1. Mean depth per site per population

```
/newhome/aj18951/1a_Aricia_agestis_GWASdata/03_variants

vcftools --vcf AAgestis.261_FINAL.newnames.vcf --site-depth

```

Plot
```
Mean depth per site in raw & filtered data
DP.sites <- read.table("out.ldepth", header=T)

pdf("a1_AriciaAgestis_DepthPerSite.pdf")
ggplot(DP.sites, aes(SUM_DEPTH)) + geom_histogram()
dev.off()


summary(DP.sites.filtered)
         CHROM            POS           SUM_DEPTH      SUMSQ_DEPTH      
 contig_365  :   82   Min.   :     4   Min.   : 2518   Min.   :   59081  
 m_scaff_3898:   80   1st Qu.:  2275   1st Qu.:13229   1st Qu.: 1643958  
 m_scaff_714 :   80   Median :  5135   Median :29046   Median : 5223654  
 contig_2942 :   79   Mean   :  7790   Mean   :30056   Mean   : 6068789  
 m_scaff_5830:   78   3rd Qu.: 10551   3rd Qu.:45418   3rd Qu.: 9723112  
 contig_16698:   77   Max.   :147561   Max.   :68598   Max.   :18003826  
 (Other)     :62578                                                      
   dataset         
 Length:63054      
 Class :character  
 Mode  :character  
                   
                   
summary(DP.sites)
          CHROM             POS           SUM_DEPTH      SUMSQ_DEPTH      
 m_scaff_6129:   176   Min.   :     4   Min.   :    1   Min.   :       1  
 m_scaff_5252:   168   1st Qu.:  2197   1st Qu.:    4   1st Qu.:       9  
 m_scaff_6232:   153   Median :  5058   Median :   39   Median :     226  
 contig_2942 :   152   Mean   :  7780   Mean   : 7724   Mean   : 1528150  
 m_scaff_910 :   150   3rd Qu.: 10497   3rd Qu.: 4038   3rd Qu.:  390659  
 m_scaff_714 :   144   Max.   :147699   Max.   :71626   Max.   :18744992  
 (Other)     :281149                                                      
```

![alt_txt][Fig3]

[Fig3]:https://user-images.githubusercontent.com/12142475/109176648-ef576980-777e-11eb-95b9-4fc630358020.png



#### 2. Mean Depth per individual and per pop

```
vcftools --vcf AAgestis.261_FINAL.newnames.vcf --depth
```

Plot of mean depth per individual grouped by population: 
/newhome/aj18951/1a_Aricia_agestis_GWASdata/03_variants

```
module load languages/R-4.0.3-gcc9.1.0

R version 4.0.3 (2020-10-10) -- "Bunny-Wunnies Freak Out"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

library(ggplot2)

DP.indivs <- read.table("out.idepth", header=T)
head(DP.indivs)
DP.indivs$pop <- gsub("_.*_.*", "", DP.indivs$INDV)
head(DP.indivs)

pdf("1a_AriciaAgestis_MeanDP.pdf")
ggplot(DP.indivs, aes(x=pop, y=MEAN_DEPTH)) + geom_boxplot()
dev.off()
```


![alt_txt][Fig2]

[Fig2]:https://user-images.githubusercontent.com/12142475/109176002-4446b000-777e-11eb-97bb-deb21be10b41.png


What is the mean depth per indiv?
```
summary(DP.indivs$MEAN_DEPTH)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  7.528 125.299 159.470 175.929 199.018 879.364 
```



#### 3. Number of variants per population (with individual variation)


```
vcftools --vcf AAgestis.261_FINAL.newnames.vcf --missing-indv
```


Plot
```
out.imiss <- read.table("out.imiss", header=T)
out.imiss$N_Variants <- (out.imiss$N_DATA-out.imiss$N_MISS)
out.imiss$pop <- gsub("_.*_.*", "", out.imiss$INDV)

pdf("1a_AriciaAgestis_nrVariantsPerPop.pdf")
ggplot(out.imiss, aes(x=pop, y=N_Variants)) + geom_boxplot()
dev.off()
```
![alt_txt][Fig4]

[Fig4]:https://user-images.githubusercontent.com/12142475/109176940-3b0a1300-777f-11eb-8014-d81b923ee6f8.png



### Filter for MAF for two datasets


#### 1. Dataset 1: Pop Gen 1% MAF

##### 1) Minimum of 1% MAF = 5 allele copies

```
vcftools --vcf AAgestis.261_FINAL.newnames.vcf --maf 0.01 --recode --recode-INFO-all --out AAgestis.261.MAF0.01.FINAL

VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AAgestis.261_FINAL.newnames.vcf
	--recode-INFO-all
	--maf 0.01
	--out AAgestis.261.MAF0.01.FINAL
	--recode

After filtering, kept 261 out of 261 Individuals
Outputting VCF file...
After filtering, kept 74738 out of a possible 122503 Sites
Run Time = 52.00 seconds

```

And check how many loci this is using thin (assuming each RAD tag is ~600bp)

```
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --thin 600

After filtering, kept 261 out of 261 Individuals
After filtering, kept 9207 out of a possible 74738 Sites
```


##### 2) Keep only loci genotyped in all populations

```
/newhome/aj18951/1a_Aricia_agestis_GWASdata/04_Outlier

grep BAR samplenames >> BAR.names
grep BCH samplenames >> BCH.names
grep BRO samplenames >> BRO.names
grep FOR samplenames >> FOR.names
grep HOD samplenames >> HOD.names
grep LYD samplenames >> LYD.names
grep MOF samplenames >> MOF.names
grep SWD samplenames >> SWD.names
grep WIS samplenames >> WIS.names

#split vcf files up for each pop
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep BCH.names --recode --recode-INFO-all --out BCH
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep BAR.names --recode --recode-INFO-all --out BAR
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep BRO.names --recode --recode-INFO-all --out BRO
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep FOR.names --recode --recode-INFO-all --out FOR
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep HOD.names --recode --recode-INFO-all --out HOD
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep LYD.names --recode --recode-INFO-all --out LYD
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep MOF.names --recode --recode-INFO-all --out MOF
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep SWD.names --recode --recode-INFO-all --out SWD
vcftools --vcf AAgestis.261.MAF0.01.FINAL.recode.vcf --keep WIS.names --recode --recode-INFO-all --out WIS



#And filter each for 50% missingness

mkdir VCF_perpop
#move all per pop vcf files into this folder

for i in $(ls *vcf); do vcftools --vcf $i --max-missing 0.5 --recode --recode-INFO-all --out $i.maxmiss; done

```

bgzip all of these (this was done on the mac) and find the intersection using bcftools. This keeps only loci that are genotyped in all of the files. Various options available.

```
module load apps/samtools-1.9.1
module load apps/tabix-0.2.6 

for i in $(ls *maxmiss.recode.vcf); do bgzip $i; done
for i in $(ls test/*); do tabix $i; done

bcftools isec -n 9 BAR.recode.vcf.maxmiss.recode.vcf.gz BCH.recode.vcf.maxmiss.recode.vcf.gz BRO.recode.vcf.maxmiss.recode.vcf.gz FOR.recode.vcf.maxmiss.recode.vcf.gz HOD.recode.vcf.maxmiss.recode.vcf.gz LYD.recode.vcf.maxmiss.recode.vcf.gz MOF.recode.vcf.maxmiss.recode.vcf.gz SWD.recode.vcf.maxmiss.recode.vcf.gz WIS.recode.vcf.maxmiss.recode.vcf.gz -p test

```

And merge all these files using bcftools
```
for i in $(ls test/*); do bgzip $i; done
for i in $(ls test/*gz); do tabix $i; done

bcftools merge test/0000.vcf.gz test/0001.vcf.gz test/0002.vcf.gz test/0003.vcf.gz test/0004.vcf.gz test/0005.vcf.gz test/0006.vcf.gz test/0007.vcf.gz test/0008.vcf.gz -O v > test/AA261.merge0.5missing.vcf

vcftools --vcf AA261.merge0.5missing.vcf 

VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AA264.merge0.5missing.vcf

After filtering, kept 261 out of 261 Individuals
After filtering, kept 55170 out of a possible 55170 Sites
Run Time = 1.00 seconds

```

This leaves 55k loci (up from ~31k in the Pop Gen paper)


##### 3. Relatedness filter

This is particularly important for the GWAS analysis. Find and remove individuals that look like they're related. 

Follow the method [here](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/2.SNPfiltering.md#3-relatedness-filter)



```
/newhome/aj18951/1a_Aricia_agestis_GWASdata/04_Outlier/VCF_perpop/test

#first thin to include only one variant per locus

vcftools --vcf AA261.merge0.5.missing.vcf --thin 600 --recode --recode-INFO-all --out AA261.merge0.5.missing.thin600

VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AA261.merge0.5.missing.vcf
	--recode-INFO-all
	--thin 600
	--out AA261.merge0.5.missing.thin600
	--recode

After filtering, kept 261 out of 261 Individuals
Outputting VCF file...
After filtering, kept 6775 out of a possible 55170 Sites
Run Time = 4.00 seconds


vcftools --vcf AA261.merge0.5.missing.thin600.recode.vcf --relatedness2
mv out.relatedness AA261.merged.thinned.relatedness2
```

Based on the King method we can estimate the relatedness coefficient we'd expect for unrelated, first order, and second order relatives. We're using a set of unlinked SNPs (~6800). 
Given the small number of loci we can't discriminate third order and unrelated individuals. But based on the theoretical distributions, all coefficients > 0.05 are likely to be related. 

Read into R and find related indivs
```
module load languages/R-4.0.3-gcc9.1.0

R

AA261.thin.relatedness2 <- read.table("AA261.merged.thinned.relatedness2", header=T)
head(AA264.thin.relatedness2)

AA261.thin.relatedness2[which(AA261.thin.relatedness2$RELATEDNESS_PHI>0.05 & AA261.thin.relatedness2$RELATEDNESS_PHI<0.5),]

            INDV1       INDV2 N_AaAa N_AAaa N1_Aa N2_Aa RELATEDNESS_PHI
8234  BCH_14_2014 LYD_29_2014    554    126   818  1270       0.1446360   ##LYD clustering with northern pops  ##ddRAD lib 4/3   ##same barcode but different libraries (AAGGCGAC)

19654 BRO_24_2013  BRO_6_2013    454    180   798   805       0.0586400   ##more related than expected         ##ddRAD lib 4/4   ##different barcodes

29190 HOD_27_2014 WIS_12_2014    564     24   655   805       0.3534250   ##HOD clusters with WIS              ##ddRAD lib 4/1   ##same barcode, different libraries
31571 HOD_39_2014 WIS_39_2014    396     15   421   822       0.2944490   ##WIS clustering within the HOD      ##ddRAD lib 1/3   ##different barcodes

57380 WIS_13_2013 WIS_15_2013    434    113   802   747       0.1342800   ##clusters away from main WIS        ##ddRAD lib 5/5   ##different barcodes. Samples next to each other
57388 WIS_13_2013 WIS_22_2013    443    124   802   792       0.1223340   ##clusters away from main WIS        ##ddRAD lib 5/5   ##different barcodes. Samples close together
57914 WIS_16_2013 WIS_24_2013    406    143   678   868       0.0776197   ##cluster in the right place         ##ddRAD lib 5/5   ##different barcodes. Samples close together

##Not included with the relatedness cut-off, but WIS_28_2013 clusters with the other WIS outliers, and have relatively high relatedness values compared with overall relatedness. 

WIS_13_2013	WIS_28_2013	444	201	802	804	0.0261519  ##PCA outliers                      ##ddRAD lib 5/5   ##different barcodes. Samples close together
WIS_15_2013	WIS_28_2013	405	190	747	804	0.0161186  ##PCA outliers                      ##ddRAD lib 5/5   ##different barcodes. Samples close together

#Mean
grep WIS_28_2013 AA261.merged.thinned.relatedness2 | awk -F "\t" '{sum+=$7}END{print sum/NR}' 
-0.394156


## Other pairs with relatedness > 0.05 based:
MOF_46_2014	SWD_45_2014	372	146	789	1132	0.041645	##both cluster in the right place ##ddRAD lib   #lib 1, barcode438/lib4, barcode 560
BRO_21_2013	SWD_46_2014	380	140	1081	724	0.0554017	##BRO slightly strange, but still within Northern group  #lib 4, barcode655/lib1, barcode 655
SWD_9_2014	WIS_37_2014	413	153	837	851	0.0633886	##both fine.    ##lib 4, 705/Lib 3, 705
```

It is unlikely that these individuals are really first or second order relatives. More likely this is contamination, or mis-labeled individuals (possibly during the library prep?)

Samples that cluster unexpectedly in the PCA: 

WIS_13_2013, WIS_15_2013, WIS_22_2013, WIS_28_2013  (in their own group). These are all related to each other.

WIS_39_2014 - clusters with HOD

LYD_29_2014 - clusters with the northern populations

Remove: (based on relatedness >0.05, And remove WIS_28_2013 because it is more related than expected to the WIS outlier cluster, and clustered with them.)  
```
LYD_29_2014   #clustering with northern pops
BRO_24_2013   #high relatedness, but clusters in the right place
BRO_6_2013    #high relatedness, but clusters in the right place
HOD_27_2014   #Group with WIS
WIS_39_2014   #WIS clustering within the HOD
WIS_13_2013   #Unique WIS cluster
WIS_15_2013   #Unique WIS cluster
WIS_22_2013   #Unique WIS cluster
WIS_28_2013   #Unique WIS cluster
WIS_16_2013   
WIS_24_2013   
HOD_27_2014   #Clusters with WIS
BRO_21_2013  
SWD_9_2014

```



#### It seems like there might have been a few samples that got swapped during the lab prep? 

1. Check if they were sequenced in the same libraries: 

The WIS samples are all from library 5. 

Two sets are from different libraries but have the same barcodes. 

BRO_24_2013 and BRO_6_2013 are from library 4. 

AND HOD_39_2014 and WIS_39_2014 had different libraries and different barcodes, but the names are really similar. 

I think it's likely there was a mix-up in the lab. It's strange that none of these samples 


2. Are there any samples with 0.5 relatedness (i.e. sampled twice but under different names?)

No. So no samples were swapped. 

3. Do the samples with high relatedness have elevated heterozygosities? (which would indicate samples were mixed rather than swapped)




#### 2. Dataset 2: Outlier analysis 5% MAF


Minimum of 5% MAF = 26 allele copies


```
vcftools --vcf AAgestis.261_FINAL.newnames.vcf --maf 0.05 --recode --recode-INFO-all --out AAgestis.261.MAF0.05.FINAL


VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AAgestis.261_FINAL.newnames.vcf
	--recode-INFO-all
	--maf 0.05
	--out AAgestis.261.MAF0.05.FINAL
	--recode

After filtering, kept 261 out of 261 Individuals
Outputting VCF file...
After filtering, kept 43541 out of a possible 122503 Sites
Run Time = 33.00 seconds

```

And check how many loci this is using thin (assuming each RAD tag is ~600bp)
```
vcftools --vcf AAgestis.261.MAF0.05.FINAL.recode.vcf --thin 600

After filtering, kept 261 out of 261 Individuals
After filtering, kept 8405 out of a possible 43541 Sites
```


